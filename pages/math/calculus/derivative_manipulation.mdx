# Derivative Manipulation

We can think of derivative formulas as falling into two categories: (1) the
specific, and (2) the general. A specific formula provides a way to
differentiate a specific example. For example, ${f(x) = x^n}$ has the
derivative ${f'(x) = nx^{n-1}.}$

In contrast, general formulas are those that apply to all functions. For
example:

- ${(f + g)' = f' + g'}$
- ${C \cdot u = C(u')}$

In the first formula above: The derivative of the sum of two functions is
the sum of the derivatives of the two functions. And in the second: The
derivative of a constant multiplied by a function is the constant
multiplied by the derivative of the function. Both specific and general
formulas are needed for polynomials.

## The Sum Rule

What is the derivative of ${f(x) = 3x^3 + 2x^2?}$ To compute this
derivative, we must apply the _sum rule for derivatives_. To do so, let's
derive the general rule. The function ${f(x) = 3x^3 + 2x^2}$ can be written
as the sum of two functions: Suppose ${g(x) = 3x^3}$ and ${j(x) = 2x^2.}$
Then ${f(x) = g(x) + j(x).}$ That said, we apply the definition of a
derivative:

$$
	f'(x) = \lim\limits_{h \to 0} \dfrac{f(x + h) - f(x)}{h}
$$

Now we substitute ${f(x + h) = g(x + h) + j(x + h)}$ and
${f(x) = g(x) + j(x):}$

$$
	f'(x) = \lim\limits_{h \to 0} \dfrac{(f(x + h) + g(x + h)) - (f(x) + g(x))}{h}
$$

Rearranging:

$$
	f'(x) = \lim\limits_{h \to 0} \left( \dfrac{f(x+h) - f(x)}{h} + \dfrac{g(x + h) - g(x)}{h} \right)
$$

And applying the sum law for limits and the definition of a derivative:

$$
	\begin{aligned} f'(x) &= \lim\limits_{h \to 0} \left( \dfrac{f(x+h)-f(x)}{h} \right) + \lim\limits_{h \to 0}\left( \dfrac{g(x+h)-g(x)}{h} \right) \\[1em] &= f'(x) + g'(x) \end{aligned}
$$

The above derivation yields the following:

> Sum Rule for Derivatives. Let ${f(x)}$ and ${g(x)}$ be differentiable
> functions. Then the derivative of the sum of ${f}$ and ${g}$ is the sum
> of the derivative of ${f}$ and the derivative of ${g:}$

$$
	\dfrac{d}{dx}(f(x) + g(x)) = \dfrac{d}{dx}(f(x)) + \dfrac{d}{dx}(g(x))
$$

Alternatively, given the differentiable functions ${r(x),}$ ${s(x),}$ and
${t(x),}$ and ${r(x) = s(x) + t(x),}$ then:

$$
	r'(x) = s'(x) + t'(x)
$$

Thus, returning to our original question, what is the derivative of
${f(x) = 3x^3 + 2x^2,}$ the derivative is simply the derivative of each
term:

> ${f'(x) = 9x^2 + 4x,}$ by the sum rule and the power rule.

## The Difference Rule

Now let's consider the opposite of addition: What is the derivative of
${p(x) = 2x^5 - x^3?}$ Here too we can think of ${p(x)}$ as consisting of
two separate functions: Given ${q(x) = 2x^5}$ and ${r(x) = x^3,}$
${p(x) = q(x) - r(x).}$ Again we apply the definition of a derivative:

$$
	p'(x) = \lim\limits_{h \to 0} \dfrac{p(x + h) - p(x)}{h}
$$

Now substitute: ${p(x + h) = q(x + h) - r(x + h)}$ and
${p(x) = q(x) - r(x):}$

$$
	p'(x) = \lim\limits_{h \to 0} \dfrac{(q(x + h) - r(x + h)) - (q(x) - r(x))}{h}
$$

Then rearranging:

$$
	p'(x) = \lim\limits_{h \to 0} \left( \dfrac{q(x + h) - q(x)}{h} - \dfrac{r(x + h) + r(x)}{h} \right)
$$

Applying the sum law for limits and the definition of a derivative:

$$
	\begin{aligned} p'(x) &= \lim\limits_{h \to 0} \left(\dfrac{q(x + h) - q(x)}{h}\right) - \lim\limits_{h \to 0} \left(\dfrac{r(x + h) - r(x)}{h}\right) \\[1em] &= q'(x) - r'(x) \end{aligned}
$$

From our analysis, we have the following rule:

> _Difference Rule for Derivatives_. Let ${f(x)}$ and ${g(x)}$ be
> differentiable functions. The derivative of the difference of ${f}$ and
> ${g}$ is the difference of the derivative of ${f}$ and ${g:}$

$$
	\dfrac{d}{dx}(f(x) - g(x)) = \dfrac{d}{dx}(f(x)) - \dfrac{d}{dx}(g(x))
$$

Alternatively, given the differentiable functions ${r(x),}$ ${s(x),}$ and
${t(x),}$ and that ${r(x) = s'(x) - t'(x):}$

$$
	r'(x) = s'(x) - t'(x)
$$

Applying our newly derived rule, the derivative of ${p(x) = 2x^5 - x^3}$
is:

> p'(x) = 10x^4 - 3x^2,}$ by the difference rule and power rule.

## Constant Multiple Rule

What is the derivative of ${f(x) = x^3 - x^2\left(\dfrac{\pi}{2}\right)?}$
This may seem complex, but we know enough to handle this. To begin with,
the term ${\dfrac{\pi}{2}}$ is just a constant. Thus, we can really write
this function as: ${f(x) = C(g(x)),}$ where ${g(x) = x^3 - x^2}$ and
${C = \dfrac{\pi}{2}.}$ Let's come up with a rule for computing the
derivative of ${f(x) = C(g(x)).}$

Because we can factor out constants from limits, applying the derivative
definition is straightforward. First, the derivative of ${f'(x)}$ is the
derivative ${(C(g(x)))'.}$ Thus:

$$
	\begin{aligned} f'(x) = (C(g(x)))' &= \lim\limits_{h \to 0} \dfrac{Cg(x + h) - Cg(x)}{h} \\[1em] &= C \lim\limits_{h \to 0} \dfrac{g(x+h) - g(x)}{h} \\[1em] &= Cg'(x) \end{aligned}
$$

From our derivation above, we have the following rule:

> _Constant Multiple Rule_. Given the function ${Cf(x),}$ where ${f(x)}$ is
> differentiable and ${C}$ is a constant:
>
> $$
> 	\dfrac{d}{dx}Cf(x) = C \cdot \dfrac{d}{dx}f(x)
> $$

Thus, the derivative of ${f(x) = x^3 - x^2\left(\dfrac{\pi}{2}\right)}$ is
a simple application of the constant multiple rule, difference rule, and
power rule:

$$
	f'(x) = (3x^2 - 2x)\left(\dfrac{\pi}{2}\right)
$$

## The Product Rule

It may be tempting to think that the derivative of a product is the product
of the derivatives. This is wrong, and we've already seen why. Given the
function ${f(x) = x^2,}$ the derivative of ${f}$ is ${f'(x) = 2x.}$
However, the function ${f(x) = x^2}$ can be written as
${f(x) = x \cdot x.}$ If it were the case the derivative of a product is
the product of the derivatives, then we would have
${\frac{d}{dx} (x^2) = \frac{d}{dx}(x) \cdot \frac{d}{dx}(x) = 1 \cdot 1 = 1.}$
Wrong. So what is the rule for products?

Well, let's apply the definition of a derivative. Suppose we have two
functions, ${f(x)}$ and ${g(x),}$ both of which are differentiable. Now
let's say that the function ${k(x)}$ is the product of these two functions:

$$
	k(x) = f(x)g(x)
$$

Now apply the definition of a derivative to the function ${k(x):}$

$$
	k'(x) = \lim\limits_{h \to 0} \dfrac{f(x + h)g(x + h) - f(x)g(x)}{h}
$$

Let's apply the old trick of adding zero. We add and subtracting
${f(x)g(x + h)}$ in the numerator:

$$
	k'(x) = \lim\limits_{h \to 0} \dfrac{f(x + h)g(x + h) - f(x)g(x + h) + f(x)g(x + h) - f(x)g(x)}{h}
$$

Using the associative property, let's group the terms to break the
quotient:

$$
	k'(x) = \lim\limits_{h \to 0} \left( \dfrac{f(x + h)g(x + h) - f(x)g(x + h)}{h} \right) + \lim\limits_{h \to 0} \left( \dfrac{f(x)g(x + h) - f(x)g(x)}{h} \right)
$$

Applying the associative property again:

$$
	k'(x) = \lim\limits_{h \to 0} \left( \dfrac{f(x + h) - f(x)}{h} \cdot g(x + h) \right) + \lim\limits_{h \to 0} \left( \dfrac{g(x + h) - g(x)}{h} \cdot f(x) \right)
$$

Now, we know that ${g(x)}$ is differentiable (by assumption), so it follows
that ${g(x)}$ is continuous. And since ${g(x)}$ is continuous,
${\lim\limits_{h \to 0}g(x + h) = g(x).}$ Hence:

$$
	\begin{aligned} k'(x) &= \underbrace{\cancel{\lim\limits_{h \to 0} \dfrac{f(x + h) - f(x)}{h}}}_{f'(x)} \cdot \underbrace{\cancel{\lim\limits_{h \to 0} g(x + h)}}_{g(x)} + \underbrace{\cancel{\lim\limits_{h \to 0} \dfrac{g(x + h) - g(x)}{h}}}_{g'(x)} \cdot \underbrace{\cancel{\lim\limits_{h \to 0} f(x)}}_{f(x)} \\ &= f'(x)g(x) + g'(x)f(x) \end{aligned}
$$

We now have a general derivative formula, the product rule:

> _Product Rule_. Given functions ${f}$ and ${g,}$ the derivative of
> ${fg,}$ denoted ${(fg)',}$ is the sum of the derivative of the function
> ${f,}$ denoted ${f',}$ times ${g,}$ and the derivative of the function
> ${g,}$ denoted ${g',}$ times ${f.}$ I.e.,
>
> $$
> 	(fg)' = f'g + fg'
> $$

For example, suppose we are given the functions ${f(x) = x^n}$ and
${g(x) = \sin x.}$ The product of these functions:

$$
	(f \cdot g)(x) = x^n \sin x
$$

What is the derivative of ${(f \cdot g)?}$ We apply the product rule:

$$
	\begin{aligned}
		(f \cdot g)' &= f'g + fg'
		&= (x^n)' \sin x + (x^n) (\sin x)
		&= (nx^{n-1})(\sin x) + (x^n)(\cos x)
	\end{aligned}
$$

## Quotient Rule

What is the derivative of ${t(x) = \dfrac{5x + 1}{3x - 4}?}$ For this, we
need another rule. Never, ever, ever, think that
${\frac{d}{dx} \dfrac{f(x)}{g(x)} = \dfrac{\frac{d}{dx}(f(x))}{\frac{d}{dx}(g(x))}.}$
This is absolutely wrong, and it is one of the most common mistakes made
among calculus newcomers.

As always, let's generalize our problem, and construct a rule. Suppose
${f(x) = 5x + 1}$ and ${g(x) = 3x - 4.}$ Thus,
${t(x) = \dfrac{f(x)}{g(x)}.}$ Accordingly, we want to compute
${\left(\dfrac{g}{j}\right)'.}$ Applying the quotient rule:

$$
	\small
	\begin{aligned}
			\left( \dfrac{f}{g} \right)' &= \lim\limits_{h \to 0} \dfrac{ \dfrac{f(x+h)}{g(x+h)} - \dfrac{f(x)}{g(x)} }{h} \\[1em]
			
			&= \lim\limits_{h \to 0} \dfrac{1}{h} \dfrac{f(x+h)g(x) - f(x)g(x+h)}{g(x+h)g(x)} \\[1em]

			&= \lim\limits_{h \to 0} \dfrac{1}{h} \dfrac{f(x+h)g(x) - f(x)g(x) + f(x)g(x) + f(x)g(x) - f(x)g(x+h)}{g(x+h)g(x)} \\[1em]

			&= \lim\limits_{h \to 0} \dfrac{1}{g(x+h)g(x)} \dfrac{f(x+h)g(x) - f(x)g(x) + f(x)g(x) - f(x)g(x+h)}{h} \\[1em]
			
			&= \lim\limits_{h \to 0} \dfrac{1}{g(x+h)g(x)} \left( \dfrac{f(x+h)g(x) - f(x)g(x)}{h} + \dfrac{f(x)g(x) - f(x)g(x+h)}{h} \right) \\[1em]
			
			&= \lim\limits_{h \to 0} \dfrac{1}{g(x + h)g(x)} \left( g(x) \dfrac{f(x + h) - f(x)}{h} - f(x) \dfrac{g(x+h) - g(x)}{h} \right) \\[1em]
			
			&= \dfrac {1} {\left(\lim\limits_{h \to 0}g(x+h)\right)\left(\lim\limits_{h \to 0}g(x)\right)} \left(\left(\lim\limits_{h \to 0}g(x)\right) \left(\lim\limits_{h \to 0} \dfrac {f(x+h) - f(x)} {h}\right) - \left(\lim\limits_{h \to 0}f(x)\right) \left( \lim\limits_{h \to 0} \dfrac{g(x + h) - g(x)}{h}\right)\right) \\[1em]
			
			&= \dfrac{1}{\underbrace{\cancel{\left(\lim\limits_{h \to 0}g(x+h)\right)}}_{g(x)}\underbrace{\cancel{\left(\lim\limits_{h \to 0}g(x)\right)}}_{g(x)}} \left(\underbrace{\cancel{\left(\lim\limits_{h \to 0}g(x)\right)}}_{g(x)} \underbrace{\cancel{\left(\lim\limits_{h \to 0} \dfrac {f(x+h) - f(x)} {h}\right)}}_{f'(x)} - \underbrace{\cancel{\left(\lim\limits_{h \to 0}f(x)\right)}}_{f(x)} \underbrace{\cancel{\left( \lim\limits_{h \to 0} \dfrac{g(x + h) - g(x)}{h}\right)}}_{g'(x)}\right) \\[1em]
			
			&= \dfrac{1}{g(x)g(x)} \left( g(x)f'(x) - f(x)g'(x) \right) \\[1em]

			&= \dfrac{f'g - fg'}{g^2}
	\end{aligned}
$$

From the derivation above, we have the following rule:

> _Quotient Rule_. Given functions ${f}$ and ${g,}$ the derivative of
> ${\dfrac{f}{g},}$ denoted ${\left(\dfrac{f}{g}\right)',}$ is provided by
> the following:
>
> $$
> 	\left(\dfrac{f}{g}\right)' = \dfrac{f'g - fg'}{g^2}
> $$

Accordingly, the derivative of ${t(x) = \dfrac{5x + 1}{3x - 4}}$ is:

$$
	\begin{aligned} t'(x) &= \dfrac{\frac{d}{dx}(5x + 1) \cdot (3x - 4) - (5x + 1) \cdot \frac{d}{dx}(3x - 4)}{(3x - 4)^2} \\[1em] &= \dfrac{(5)(3x - 4) - (5x + 1)(3)}{(3x - 4)^2} \\[1em] &= \dfrac{15x - 20 - 15x - 3}{(3x - 4)^2} \\[1em] &= - \dfrac{23}{(3x - 4)^2} \end{aligned}
$$

## Chain Rule

In many of the previous examples, we abstracted the function's terms to
arrive at a more general rule. For example, given the function
${f(x) = x^3 - (1/x),}$ we would write ${f(x) = t(x) - s(x),}$ where
${t(x) = x^3}$ and ${s(x) = 1/x.}$ We would then arrive at a derivative
from this more abstracted form. This technique results from two
observations: First, every function can be expressed as the combination of
smaller functions. Borrowing from computer science, we might call these
smaller functions helper functions. For example, silly as it may be, the
function ${f(x) = x^2}$ can be written as ${f(x) = g(x),}$ where
${g(x) = x^2.}$ Or it can be written as ${f(x) = (g(x))^2}$, where
${g(x) = x.}$ Second, there are really only three ways to combine
functions.

First, we can add functions. For example, the function
${f(x) = \sin x + x^2}$ can be written as ${f(x) = g(x) + h(x),}$ where
${g(x) = \sin x}$ and ${h(x) = x^2.}$ The ability to add functions implies
the ability to subtract functions, since addition is really just the
addition of a negative. For example, the function ${a(x) = x^3 - x^2}$ can
be written as ${a(x) = b(x) + c(x),}$ where ${b(x) = x^3}$ and
${c(x) = -x^2.}$

Second, we can multiply functions. The function
${\alpha(x) = (\sin x)(x^2)}$ can be written as
${\alpha(x) = \beta(x) \gamma(x),}$ where ${\beta(x) = \sin x}$ and
${\gamma(x) = x^2.}$ The ability to multiply functions implies the ability
to divide functions, since division is just multiplication with the
reciprocal. The function ${L(x) = \dfrac{\sin x}{x^5}}$ can be written as
${L(x) = M(x) \cdot N(x)}$ where ${M(x) = \sin x}$ and
${N(x) = \dfrac{1}{x^5}.}$

Third, we can compose, or nest, functions. For example, the function
${f(x) = (x^2 - 1)^2}$ can be written as ${f(x) = (g(x))^2,}$ where
${g(x) = x^2 - 1.}$ Similarly, the function ${\kappa(x) = \sin (x^3)}$ can
be written as ${\kappa(x) = \sin (\lambda(x)),}$ where
${\lambda(x) = x^3.}$

Borrowing again from computer science, these are the three means of
combination. The remarkable aspect of functions is that every function can
be written and rewritten, or expressed, with just these three means.

So far, we've used our abstraction technique for the first two means:
addition and multiplication. What we haven't used it for, however, is with
composition. This limitation leads to some problems. We haven't yet seen a
way to apply the technique to a function like ${s(a) = (a^2 - 1)^2.}$
Fortunately, we can simply expand this function: ${s(a) = a^4 - 2a^2 + 1,}$
then apply our familiar rules.

Expansion, however, begins falling apart once we have something like
${(29a^4 - 17a^3 + 32a^2 - 17)^{15}.}$ This is a polynomial that would be
messy to expand. We'd sooner exhaust ourselves before seeing the
polynomial's final form.

Worse, neither expansion nor our original method of generalization would
help with functions like ${f(x) = \cos (x^2)}$ or
${t(x) = \tan \left(\dfrac{1}{2x^3 - x}\right).}$ With the rules we have
thus far, it isn't exactly clear how we would compute the derivatives for
these functions. All these functions are called composite functions &mdash;
functions combined through composition, or nesting. The most efficient way
to compute their derivatives is with a new theorem: the chain rule.

To understand the chain rule, we must first review how composite functions
work. Composite functions are simply compositions of functions. Our
original method of generalization is applicable to composing functions.
With the composite function ${y = (x^3 - 1)^{100},}$ we generalize
${x^3 - 1}$ to ${u = x^3 - 1.}$ Following this generalization,
${y = u^{100}.}$ Now, let's compute ${\dfrac{dy}{du}:}$

$$
	y = u^{100}
	\dfrac{dy}{du} = 100u^{99}
$$

That was a straightforward application of the power rule. Now let's compute
the derivative of ${\dfrac{du}{dx}:}$

$$
	u = x^3 - 1
	\dfrac{du}{dx} = u' = 3x^2
$$

So now we have these two results:

$$
	\dfrac{dy}{du} = 100u^{99}
	\dfrac{du}{dx} = u' = 3x^2
$$

But, what we ultimately want to find is ${\dfrac{dy}{dx}.}$ Now, notice the
way Leibniz's notation looks:

$$
	\dfrac{dy}{du}
	\dfrac{du}{dx}
$$

Those look an awful lot like fractions, and it's tempting to multiply them
and cancel:

$$
	\dfrac{dy}{\cancel{du}} \cdot \dfrac{\cancel{du}}{dx} = \dfrac{dy}{dx}
$$

Let's put a pin on this observation for now, but we'll revisit it shortly.
What we should do instead is think a little more carefully about what it
means to compute the derivative of a nested function, say ${f(g(x)).}$ If
suppose that ${y = g(x),}$ then ${f(g(x)) = f(y).}$ Looking at it this way,
we can see that ${g(x)}$ outputs a ${y,}$ and that ${y}$ is an input for
${f.}$ Now let's say that ${z = f(x).}$ Viewing it this way, when we ask
for the derivative of ${f(g(x)),}$ what we're really asking for is, how
quickly (or slowly), does ${f}$ change as ${x}$ changes?

The answer to that question is the derivative. We know that a derivative is
simply the application of a limit to the quotient rule. Thus, what we want
to do is to consider the Newton quotient of the compositve function
${f \circ g:}$

Suppose ${f}$ has a derivative at ${g(x)}$ and ${g}$ has a derivative at
${x.}$ Then, by Newton's quotient:

$$
	\dfrac{f(x + h) - f(x)}{h} = \dfrac{f(g(x + h)) - f(g(x))}{h}
$$

This expression is a bit of an eye sore, so we'll replace some of the terms
with simpler variables. Suppose:

$$
	u = g(x)
	k = g(x + h) - g(x)
$$

Notice that with the above substitutions, ${k}$ depends on ${h.}$ As ${h}$
approaches 0, ${k}$ tends to 0. Bearing this in mind, we can the
corresponding terms and arrive at the following:

$$
	\dfrac{f(u + k) - f(u)}{h}
$$

This looks very similar to the derivative ${f'(u),}$ but we have ${h}$ in
the denominator and ${k}$ in the numerator. Recall that ${k}$ depends on
${h.}$ And because ${k}$ depends on ${h,}$ we have two cases to consider:
${k = 0}$ and ${k \neq 0.}$

The easier (and more common) case is when ${k \neq 0,}$ so let's deal with
it it first. Suppose ${k \neq 0.}$ If ${k \neq 0,}$ then we can multiply
and divide the our equation by ${k:}$

$$
	\dfrac{f(u + k) - f(u)}{k} \cdot \dfrac{k}{h} = \dfrac{f(u + k) - f(u)}{k} \cdot \dfrac{g(x + h) - g(x)}{h}
$$

Examining the resulting equation, when ${h}$ approaches ${0,}$ several
things occur. First, the quotient:

$$
	\dfrac{g(x + h) - g(x)}{h}
$$

tends to ${g'(x).}$ Second, ${k \to 0}$ (&#8220;${k}$ tends towards
0&#8221;) as ${h \to 0}$ because ${k = g(x + h) - g(x)}$ and ${g}$ is
continuous at ${x}$ (by our first assumptions). Thus, the quotient:

$$
	\dfrac{g(x + h) - g(x)}{h}
$$

approaches ${g'(x)}$ as ${h \to 0,}$ and the quotient:

$$
	\dfrac{f(u + k) - f(u)}{k}
$$

approaches ${f'(u)}$ as ${h \to 0.}$ Hence, we have the following rule:

$$
	(f \circ g)'(x) = f'(g(x)) \cdot g'(x)
$$

The above rule, however, only applies when ${k \neq 0.}$ We must still
consider the case where ${k = 0.}$ This is somewhat of an edge case, but
because the possibility exists, we must address it. Otherwise, our
preceding wouldn't apply.

First, say we have a number ${u}$ such that ${f(u)}$ is defined. By the
limit of Newton's quotient, we know that:

$$
	\lim\limits_{h \to 0} \dfrac{f(u + k) - f(u)}{k} = f'(u)
$$

Encapsulating the above:

$$
	\varphi(k) = \dfrac{f(u + k) - f(u)}{k} - f'(u)
$$

It follows then that, as ${k}$ approaches 0, ${\varphi(k) = 0.}$ In other
words:

$$
	\lim\limits_{k \to 0} \varphi(k) = \dfrac{f(u + k) - f(u)}{k} - f'(u) = 0
$$

Multiplying both sides by ${k,}$ we have:

$$
	k \cdot \varphi(k) = f(u + k) - f(u) - kf'(u)
$$

We can rewrite this as:

$$
	f(u + k) - f(u) = k \cdot f'(u) + k \cdot \varphi(k)
$$

Consider what happens when ${k \neq 0.}$ The equation is holds. But if
${k = 0,}$ the equation breaks down, because ${\varphi(k)}$ leaves a 0 in
the denominator. We can avoid this by supposing that ${\varphi(k) = 0,}$ in
which case the equation holds when ${k = 0,}$ since doing so would simply
yield:

$$
	f(u) - f(u) = 0
$$

Of course, this is true. With this in mind, let's say ${u = g(x)}$ and
${k = g(x + h) - g(x).}$ Then as ${h}$ tends towards 0, so too does ${k.}$
Now, recall that the Newton quotient for the function ${f \circ g}$ is:

$$
	\dfrac{f(g(x + h)) - f(g(x))}{h} = \dfrac{f(u + k) - f(u)}{h}
$$

Based on our previous analysis, it follows that:

$$
	\begin{aligned} \dfrac{f(g(x + h)) - f(g(x))}{h} &= \dfrac{f(u + k) - f(u)}{h} \\ &= \dfrac{k \cdot f'(u) + k \cdot \varphi(k)}{h} \end{aligned}
$$

Substituting the value for ${k,}$ we have:

$$
	\begin{aligned} \dfrac{f(g(x + h)) - f(g(x))}{h} &= \dfrac{f(u + k) - f(u)}{h} \\ &= \dfrac{k \cdot f'(u) + k \cdot \varphi(k)}{h} \\ &= \dfrac{g(x + h) - g(x)}{h} f'(u) + \dfrac{g(x + h) - g(x) - g(x)}{h} \varphi(k) \end{aligned}
$$

Now we take the limit as ${h}$ as 0. Applying this limit, we see that the
first term approaches ${g'(x)f'(u).}$ Given that the limit of
${\varphi(k)}$ as ${h \to 0}$ or ${k \to 0}$ is 0, applying the limit to
the second term results in:

$$
	\lim\limits_{h \to 0} \dfrac{g(x + h) - g(x)}{h} \varphi(k) = g'(x) \cdot 0 = 0
$$

Accordingly, we have the rule:

$$
	f \circ g(x) = f'(g(x))g'(x)
$$

Formally stating this rule:

> _The Chain Rule_. Suppose ${f}$ and ${g}$ are functions. For all ${x}$ in
> the domain of ${g}$ for which ${g}$ is differentiable at ${x}$ and ${f}$
> is differentiable at ${g(x),}$ the derivative of the composite function
> ${h(x) = (f \circ g)(x) = f(g(x))}$ is given by:
>
> $$
> 	h'(x) = f'(g(x))g'(x)
> $$

Alternatively, if ${y}$ is a function of ${u,}$ and ${u}$ is a function of
${x,}$ then:

$$
	\dfrac{dy}{dx} = \dfrac{dy}{du} \cdot \dfrac{du}{dx}
$$

Once more we see that the chain rule applies even when ${k = 0.}$ This
proves that the chain rule applies in general. Having proved the chain
rule, we can now see that we can rest easy succumbing to our previous
temptation:

$$
	\dfrac{dy}{\cancel{du}} \cdot \dfrac{\cancel{du}}{dx} = \dfrac{dy}{dx}
$$

This is because the chain rule can be expressed by the formula:

$$
	\dfrac{d(f \circ g)}{dx} = \dfrac{df}{du} \cdot \dfrac{du}{dx}
$$

With the chain rule, derivatives of composite functions behave as if we
could cancel ${du.}$ For example, suppose we're asked to compute the
following derivative:

$$
	\dfrac{d}{dx} (3x^2 - 4)^{100}
$$

We can compute this derivative quickly with the chain rule. First, we need
the two terms, ${\dfrac{dy}{du}}$ and ${\dfrac{du}{dx}.}$ The variable
${u}$ embodies the outer function. ${u = 3x^2 - 4.}$ Thus:

$$
	\begin{aligned} \dfrac{d}{dx} (3x^2 - 4)^{100} &= \dfrac{dy}{du} \cdot \dfrac{du}{dx} \\[1em] &= \dfrac{d}{du}(u^{100}) \cdot \dfrac{d}{dx}(3x^2 - 4) \\[1em] &= 100u^{99} \cdot 6x \\[1em] &= 100(3x^2 - 4)^{99} \cdot 6x \\[1em] &= 600x(3x^2 - 4)^{99} \end{aligned}
$$

## Higher-order Derivatives

The mathematician Hugo Rossi famously quipped, &#8220;In the fall of 1972,
President Nixon announced that the rate of increase of inflation was
decreasing. This was the first time a sitting president used the third
derivative to advance his case for reelection.&#8221; What is this third
derivative? It's simply a derivative of a derivative &mdash; a higher-order
derivative.

Higher derivatives are denoted ordinally. I.e., the &#8220;second
derivative,&#8221; the &#8220;third derivative,&#8221; etc. For example,
velocity is the first derivative of the position vector with respect to
time, representing the change in an object's position over time.
Acceleration is the second derivative of the position vector with respect
to time, representing the moving object's change in velocity (e.g., how
fast does this car go from 0mph to 100mph?). Jerk is the third derivative
of the position vector with respect to time, representing the change in
acceleration. Somewhat humorously and non-standardized: A snap is the
fourth derivative representing the change in jerk. Crackle is the fifth
derivative representing the change in snap. Pop is the sixth derivative
representing the change in crackle.

The rules we've covered thus far equally apply to the computation of
higher-order derivatives. For example, given ${u(x) = \sin x,}$ the first
derivative is ${u' = \cos x.}$ The second derivative is
${(u')' = (\cos x)' = - \sin x.}$

There are several forms of notation for higher derivatives:

- ${f'(x) \equiv D f \equiv \dfrac{df}{dx} \equiv \dfrac{d}{dx} f}$

- ${f''(x) \equiv D^2 f \equiv \dfrac{d^2f}{dx^2} \equiv (\dfrac{d}{dx})^2
f}$

- ${f'''(x) \equiv D^3 f \equiv \dfrac{d^3f}{dx^3} \equiv
(\dfrac{d}{dx})^3 f}$

- ${f^{(n)}(x) \equiv D^n f \equiv \dfrac{d^nf}{dx^n} \equiv
(\dfrac{d}{dx})^n f}$

The symbols ${D}$ and ${\dfrac{d}{dx}}$ are operators we can apply to
functions. Applying such operators, the derivative of the function is
returned.
