import { Plot } from "../../../components/hago";
import { BarPlot } from "../../../components/illus/components/BarPlot/BarPlot";

<Head>
  <title>Probability Introduction</title>
  <meta name={`description`} content={`Notes on probability.`} />
</Head>

# Classical Probability

_These notes provide an overview of probability._

1. [Models](#models)
   1. [When is a Model Correct?](#when-is-a-model-correct)
   2. [How Do We Verify a Model?](#how-do-we-verify-a-model)
2. [What is an Outcome?](#what-is-an-outcome)
3. [What is an Event?](#what-is-an-event)
4. [What is a probability?](#what-is-a-probability)
   1. [What is a Discrete Sample Space?](#what-is-a-discrete-sample-space)
   2. [`P{A xor B}`](#pa-xor-b)
   3. [`P{A or B}`](#pa-or-b)
5. [Probability Distribution](#probability-distribution)
6. [Enumerating Events](#enumerating-events)
   1. [Sequence](#sequence)
      1. [Counting Sequences](#counting-sequences)
   2. [Permutation](#permutation)
      1. [Counting Permutations](#counting-permutations)
   3. [Combinations](#combinations)
7. [Classical Theorems](#classical-theorems)
   1. [Uniform Distribution](#uniform-distribution)
   2. [Probability of an Event](#probability-of-an-event)
   3. [Probability of ${\\bm{A}}$ or ${\\bm{B}}$](#probability-of-bma-or-bmb)
   4. [Conditional Probability](#conditional-probability)
   5. [Independent Events](#independent-events)
8. [Random Variables](#random-variables)
   1. [Functions of Random Variables](#functions-of-random-variables)
   2. [Discrete vs. Continuous Random Variables](#discrete-vs-continuous-random-variables)
   3. [Probability Mass Function](#probability-mass-function)
   4. [Expected Value](#expected-value)

## Models
> __Definition: Axiom.__ A statement accepted as true without proof.

> __Definition: Model.__ A set of axioms that describe an object.
 
_Note_. The object described by a model may be abstract (i.e., perceived only within our minds) or real (i.e., a real-world phenomenon that we can perceive with some sense).

_Example_. The Perfect Gas Law is a model of how the pressure ${P,}$ volume ${V,}$ and temperature ${T}$ of a given gas are related: ${PV = RT,}$ where ${R}$ is the gas constant.

_Example_. Set theory is a model of how collections called _sets_ can be used to provide the foundations of mathematics.

### When is a Model Correct?
A model is _correct_ if it cannot prove ${p \land \neg p.}$ That is, the model is _free of_, and _avoids_, contradictions. The process of checking whether this requirement is met is called _verification_.

### How Do We Verify a Model?
In mathematics, we verify models with the rules of _mathematical logic_ (which are themselves models, but that's a topic for another day). Models subject to the rules of mathematical logic are called _mathematical models_.

Models that have been verified often earn the postfix “theory” or the prefix “the laws of.” For example: Set Theory, Number Theory, Complexity Theory, etc. This usage of “theory” is different from “scientific theory.” Scientific theories are akin to _hypotheses_ or _conjectures_ in mathematics. Where ${x}$ is some noun, the syntax “${x}$ theory” in mathematics is akin to “the laws of ${x}$” in the sciences. This outline focuses on one particular theory, _probability theory_.

Theories are what we use to create further models. For example: Models subject to _the laws of geometry_ are called _geometric models_. Models subject to _number theory_ are called _number theoretic models_. And for our purposes: Models subject to probability theory are called _probabilistic models_.

## What is an Outcome?
> __Definition: Outcome.__ An _outcome_, or _sample point_, is the simplest object in a probabilistic model—it is an entity that cannot be simplified further.

In other words, a _outcome_ is (1) where a probabilistic model starts, and (2) where a probabilistic model ends. What the point _represents_ is entirely up to us. It could be a person, a number, a fruit, a cat, whatever. The key idea is that a sample point is _axiomatic_—it's a guard rail, beyond which is infinite descent: What’s an ${x}$? An ${x}$ is a ${y.}$ What’s a ${y}$? A ${y}$ is a ${z.}$ What’s a ${z}$? A ${z}$ is a ... Without the sample point, we’d get nowhere.

## What is an Event?
> __Definition: Event.__ An _event_ is a set of outcomes.

That is all an event is—a set of outcomes. Keeping the definition bare simple gives its user more flexibility. For basic probability, it’s easiest to think of an event as a set of outcomes from running an _experiment_.

> __Definition: Experiment.__ An experiment is a procedure that can be infinitely repeated, with each result corresponding to an outcome in a well-defined set.

The phrase _well-defined_ is short for “no surprises” or “unambiguous.” Saying that ${A}$ is the well-defined set ${\set{0,1}}$ is equivalent to saying: “Whenever you look inside ${A,}$ you'll always find ${0}$ and ${1,}$ nothing else.“ On the other hand, the set ${B=\set{0,1,\sqrt{4}}}$ is not well-defined, because ${\sqrt{4}}$ has two possible values: ${-2}$ or ${2.}$ We coud look inside ${B}$ and find ${\set{0,1,2}}$ and then later find ${\set{0,1,-2}.}$

_Example_. Tossing a coin is an experiment with two events:

$$
\set{\set{H}, \set{T}}
$$

The sample points are ${H}$ and ${T.}$ The events are ${\set{H}}$ and ${\set{T}.}$ The set of possible outcomes is the set of all events: ${\set{\set{H}, \set{T}}.}$ We call this set the __*sample space*__.

> __Definition: Sample Space.__ Let ${E}$ be an experiment. The sample space of ${E,}$ denoted ${\Ss_E,}$ or, if unambiguous, ${\Ss,}$ is the set of all events resulting from ${E.}$

Why are events defined as sets of sample points instead of the sample points themselves? Because the outcomes of an experiment aren't necessarily the simplest objects. Consider the following experiment, written in some pseudocode.

~~~tsx
1. let result = []
2. let toss1 = tossCoin()
3. result.insert(toss1)
4. let toss2 = tossCoin()
5. result.insert(toss2)
~~~

What are the possible values of `result`? We can have `[H,T]`, `[H,H]`, `[T,H]`, and `[T,T]`. These are the outcomes of the experiment, but they aren't sample points! Why aren't they sample points? Because each outcome can be simplified further: `H` or `T` for the first toss, and `H` or `T` for the second toss. Remember that sample points are entities that cannot be further simplified.

| Result  | Reduction           |
| ------- | ------------------- |
| `[H,H]` | `{(1,H)} ∪ {(2,H)}` |
| `[H,T]` | `{(1,H)} ∪ {(2,T)}` |
| `[T,H]` | `{(1,T)} ∪ {(2,T)}` |
| `[T,T]` | `{(1,T)} ∪ {(2,T)}` |

Thus, for any given run of the experiment, we get a set, not an element. It follows that for any given experiment, an event is a _subset_ of the sample space.

## What is a probability?
A probability is a special kind of ratio:

> __Definition: Probability.__ Let ${E}$ be an experiment with some event ${A}$ and a sample space ${\Ss.}$ The _probability_ of ${A}$ is a ratio ${\pb{A} = \card{A}/\card{\Ss},}$ where ${\card{A}}$ is the number of outcomes in ${A,}$ and ${\card{\Ss}}$ is the number of all possible outcomes of ${E.}$

We say special because it has a few more properties that separate it from other ratios:

> __Normalization Axiom.__ The probability of a sample ${S}$ is always 1: ${\pb{\Ss}=1.}$ By implication, ${\pb{\nil} = 0.}$

> __Nonnegativity Axiom.__ All probabilities are nonnegative.

> __Nonnnegativity Corollary.__ Because of the normalization axiom and the nonnegativity axiom, the probability of an event ${A}$ in the sample space ${\Ss}$ is always less than or equal to ${1.}$ I.e., ${0 \le \pb{A} \le 1.}$

> __Additivity Axiom.__ Given events ${A}$ and ${B,}$ if ${A \cap B = \nil}$ (that is, ${A}$ and ${B}$ share no outcomes), then ${\pb{A \cup B} = \pb{A} + \pb{B}.}$

Below are notations we'll use extensively. Assume ${A}$ and ${B}$ are events.

| Notation                    | Meaning                                            |
| --------------------------- | -------------------------------------------------- |
| ${\pb{A}}$                  | The probability of ${A}$                           |
| ${\pb{A^c}}$                | The probability of all outcomes not in ${A}$       |
| ${\pb{A \cup B}}$           | The probability of ${A}$ _or_ ${B}$ _or_ both      |
| ${\pb{A \dup B}}$           | The probability of ${A}$ _or_ ${B}$ _but not_ both |
| ${\pb{A \cap B}}$           | The probability of ${A}$ _and_ ${B}$               |
| ${\pb{A^c \cap B^c}}$       | The probability of _neither_ ${A}$ _nor_ ${B}$     |
| ${\pb{A \smallsetminus B}}$ | The probability of ${A}$ but not ${B}$             |
| ${\pb{B \smallsetminus A}}$ | The probability of ${B}$ but not ${A}$             |

### What is a Discrete Sample Space?
> __Definition: Discrete Sample Space.__ A sample space is _discrete_ if either of these conditions are met: (1) the sample space contains finitely many outcomes, or (2) the sample space contains infinitely many outcomes that can be arranged into a simple sequence ${o_1, o_2, o_3, \ldots}$

### `P{A xor B}`
> __Axiom.__ Let ${\Ss = \set{A,B},}$ with ${A \cap B = \nil.}$ The probability of ${A}$ or ${B,}$ but not both, occurring, is ${\pb{A \dup B} = \pb{A} + \pb{B}.}$

### `P{A or B}`
> __Axiom.__ Let ${\Ss = \set{A,B}.}$ The probability of ${A}$ or ${B,}$ or both, occurring, is ${\pb{A \cup B} = \pb{A} + \pb{B} - \pb{A \rid B}.}$


## Probability Distribution

> __~probability distribution~.__ A probability distribution ${\texttt{P}}$ is a function that assigns to each event ${E}$ a probability ${\pb{E},}$ such that: (1) ${\pb{E} \ge 0,}$ (2) ${\pb{\Omega}=1,}$ and (3) if ${A \cap B = \nil,}$ then ${\pb{A \cup B}=\pb{A} + \pb{B}.}$

It's helpful to think of probabilities as physical weights (in a classical sense). The universe (sample space) has a weight (probability). The universe also contains objects (events) which also have a weight (probability). The objects are comprised of atoms (outcomes) which also have a weight (probability).

~example~. What is the probability of rolling a 1 on a six-sided die? The sample space is ${\set{1,2,3,4,5,6}.}$ The event ${\set{1}}$ has a cardinality of one. Hence, we have ${\pb{1} = 1/6.}$

~example~. What is the probability of rolling a 1 or 2 on a six-sided die? The sample space is ${\set{1,2,3,4,5,6}.}$ The event ${\set{1,2}}$ has a cardinality of 2. Hence, we have ${\pb{1,2} = 2/6 = 1/3.}$

~remark on percentages~. Generally, we express probabilities in terms of rational numbers. There isn't anything wrong with using percentages, but it can lead to confusion, given the different contexts in which percentages are used. In some contexts, they're used to denote fractions, in others, measures of change. For example, suppose we're told that ${\pb{A}=40\%,}$ and that an event ${B}$ has a ${25\%}$ higher probability than ${A.}$ Does this mean ${\pb{B}=40\% + (25\% \times 40\%)=50\%,}$ or that ${\pb{B}=25\% + 40\%=65\%?}$ The matter is resolved by making additional statements for clarification, but we don't need to make such statements if we simply used rationals.

## Enumerating Events
### Sequence
> __~definition: sequence~.__ A _sequence_ is an arrangement of objects in a definite order, possibly containing duplicates.

#### Counting Sequences
> __~theorem~.__ Let ${P}$ be an experiment of ${\px{k_1, k_2, \ldots, k_{n-1}, k_n}}$ steps, where each step ${k_i}$ consists of ${d}$ decisions, regardless of the decision at ${k_{i-1}.}$ Then there are
> 
> $$
>   d_1 \times d_2 \times \ldots \times d_{n-1} \times d_n
> $$
> 
> possible outcomes of ${P.}$

### Permutation
> __~definition: permutation~.__ A _permutation_ is an arrangement of objects in a definite order, without duplicates.

#### Counting Permutations 
> __~theorem~.__ Let ${P}$ be an experiment of ${\px{k_1, k_2, \ldots, k_{n-1}, k_n}}$ steps, such that, if a decision ${n_i}$ was made at step ${k_i,}$ the decision ${n_i}$ cannot be made at ${k_j}$ for all ${j \gt i.}$ Then there are
> 
> $$
>   n! = n \times (n-1) \times (n-2) \times \ldots \times 3 \times 2 \times 1
> $$
> 
> possible outcomes of ${P.}$ We define ${0! = 1.}$

> __~theorem~.__ Let ${S}$ be a set of ${n}$ decisions. Let ${P}$ be an experiment of making ${k}$ decisions from ${S}$ in permutation. Then there are
> 
> $$
>   _nP_k = \frac{n!}{\px{n - k}!}
> $$
> 
> possible outcomes of ${P.}$

### Combinations
> __~definition: combination~.__ A _combination_ is a selection of objects without regard to order.

> __~theorem~.__ Let ${S}$ be a set of ${n}$ options. Let ${P}$ be an experiment of choosing ${k}$ options from ${S.}$ Then there are
> 
> $$
>   _nC_k = \dbinom{n}{k} = \frac{n!}{k!\px{n-k}!}
> $$
> 
> possible outcomes of ${P.}$

## Classical Theorems

### Uniform Distribution
> __~definition: uniform distribution~.__ Let ${\Omega}$ be a sample space of ${n}$ outcomes. The _uniform distribution_ assigns the probability of ${1/n}$ to each outcome ${\textmd{O} \in \Omega.}$

### Probability of an Event
__~definition~.__ The probability of an event ${E}$ is the sum of the probabilities of the outcomes in ${E:}$

$$
  \pb{E} = \dsum{\textmd{O}~\in E}{}\pb{\textmd{O}}.
$$

> __~theorem~.__ Let ${E_1, E_2, \ldots, E_n}$ be disjoint events in a sample space ${\Omega.}$ Then

$$
  \pb{\bigcup\limits_{i}E_i} = \dsum{i}{}\pb{E_i}.
$$

### Probability of ${\bm{A}}$ or ${\bm{B}}$
The probability of ${A}$ _or_ ${B}$ occurring results from the sum rule of combinatorics.

> __~theorem~.__ let ${E_1}$ and ${E_2}$ be events in a sample space ${\Omega.}$ Then ${\pb{E_1 \cup E_2} = \pb{E_1} + \pb{E_2} - \pb{E_1 \cap E_2}.}$

### Conditional Probability
> __~definition: conditional probability~.__ Let ${A}$ and ${B}$ be events in a sample space ${\Omega}$ with ${\pb{B} \gt 0.}$ The _conditional probability of ${A}$ given ${B}$_, denoted ${\pb{A \mid B},}$ is defined by setting
>
> $$
>   \pb{A \mid B} = \frac{\pb{A \cap B}}{\pb{B}}.
> $$
>
> If ${\pb{B} = 0,}$ then the conditional probability of ${A}$ given ${B}$ is undefined.

### Independent Events
> __~definition~.__ Let ${A}$ and ${B}$ be events in a sample space ${\Omega.}$ We say that ${A}$ and ${B}$ are _independent_ if, and only if, ${\pb{A \cap B} = \pb{A} \by \pb{B}.}$

## Random Variables
<Fig
  link={"https://res.cloudinary.com/sublimis/image/upload/v1668575374/math/random-variable_vstl0v.svg"}
  imwidth={202}
  imheight={110}
  caption={"discrete random variable"}
  width={30}
  className='float-right'
/>

> __~definition: random variable~.__ Let ${\Ee}$ be an experiment whose outcomes are a sample space ${\Omega,}$ such that ${\pb{s}}$ is defined for each outcome ${s \in U.}$ A _random variable_ is a function ${X}$ that associates a real number ${X\px{s}}$ with each ${s \in \Omega.}$


~example~. ${\Ee}$ is an experiment of surveying the ages of residents in a neighborhood with sample space ${\Omega}$ and ${A}$ is a function mapping ${s \in \Omega}$ to ${R \subset \reals.}$ The random variable ${A\px{s}}$ is an age, where ${s}$ is an outcome of the sample space of ${\Ee.}$ Its codomain may include ${A\px{s_1} = 27}$ or ${X\px{s_2} = 34}$ or ${X\px{s_3} = 85.}$ It depends on the sample space.

~example~. There may be more than one random variable for a given sample space. Let ${\Ee}$ be the same experiment as the previous example, with sample space ${\Omega.}$ Let ${\cash{}}$ be a function from ${\Omega}$ to ${\tx{income} \subset \reals.}$ Then ${\tx{income}}$ may include ${\cash{\px{s_1}} = 40~000,}$ ${\cash{\px{s_2}} = 80~000,}$ or ${\cash{\px{s}} = 1~150~000.}$ Again, it depends on the sample space.

~remark~. The name _random variable_ is a misnomer. It isn't random, and it isn't a variable. It is a function from the sample space to real numbers.

~remark~. There's a difference between a _random variable_ and the _value of a random variable_. A _random variable_ is a function. Per set theory, it is a set of pairs ${(a,b),}$ where ${a = s}$ is an element of the domain — the sample space of an experiment — and ${b = X\px{s}}$ is an element of the codomain — the real numbers. The distinction is akin to a subroutine in computer programming.

<Algo>

1. __import__ ${survey}$ _suppose ${survey}$ is an array_
2. __function__ ${X(s)}$ _the subroutine ${X}$_
    1. __return__ ${survey\ix{s}}$ _the return of ${X}$ given ${s}$_

</Algo>

### Functions of Random Variables
> __~definition~.__ Let ${X}$ be a random variable. Then ${f \circ X}$ is called a _function of a random variable_. I.e., ${\dom{f} = \tx{codom}\px{X}.}$ The codomain of ${f}$ may be reals, integers, rationals, or natural numbers.

~example~. Let ${\Ee}$ be an experiment of taking the weights of passengers on an amusement park ride with sample space ${\Omega}$ and a random variable ${X: \Omega \mapsto \df{weight} \subset \reals.}$ Let ${f}$ be a function from ${\df{weight}}$ to ${\pint.}$ Then ${f(w) = \ceil{w}}$ is a function of a random variable.

### Discrete vs. Continuous Random Variables
<Fig
  link={"https://res.cloudinary.com/sublimis/image/upload/v1668575377/math/discrete-random-variable_h4qork.svg"}
  imwidth={206}
  imheight={122}
  caption={'discrete random variable'}
  width={40}
  className='float-right'
/>

> __~definition: discrete random variable~.__ A _discrete random variable_ is a random variable whose range is finite or countably infinite.

> __~definition: continuous random variable~.__ A _continuous random variable_ is a random variable whose codomain is a set of reals.

We address discrete random variables first then continuous random variables. Propositions about continuous random variables build upon the propositions about discrete random variables, and discrete random variables tend to be easier to reason about.

### Probability Mass Function
<Fig
  link={"https://res.cloudinary.com/sublimis/image/upload/v1668599050/math/distribution_dtze75.svg"}
  imwidth={229}
  imheight={217}
  caption={'probability distrubtion'}
  width={40}
  className='float-right'
/>

> __~definition: probability mass function~.__ Let ${X}$ be a random variable such that ${x \in \tx{codom}\px{X}.}$ A _probability mass function (PMF),_ denoted ${P_X,}$ is a function from ${\tx{codom}{\px{X}} \mapsto \ix{0,1}.}$ That is, ${P_X\px{x}}$ is the probability of ${X}$ returning the value ${x.}$

~example~. Let ${\Ee}$ be the following experiment. Given a coin, let ${\H}$ be heads and let ${\T}$ be tails. Continue to flip the coin until it lands ${\H.}$ The experiment ${\Ee}$ records the number of flips it takes to get ${\H.}$

1. What are the possible outcomes of this this experiment? Let ${X}$ be a random variable. We can land ${\H}$ on the first flip. In this case, the random variable ${X}$ takes the value one: ${P_X\px{\H}=1.}$ We can also land ${\H}$ on the second flip. The random variable takes the value two: ${P_X\px{\T\H} = 2.}$ Or the third flip: ${P_X\px{\T\T\H}=3.}$ In general:
$$
  P_X\px{\tnote{\T,\ldots,\T,}{$k-1$ times}\H} = k
$$
2. What is the probability mass function of ${X?}$ By definition, the probability mass function ${P_X}$ is the probability that ${X}$ returns the value ${k.}$ To obtain the outcome ${X(s) = k,}$ where ${s}$ is an outcome of ${\Ee,}$ is to obtain the sequence ${\T,\ldots,\T,\H.}$ The probability of obtaining this sequence is given by the geometric formula ${(1 - p)^{k-1}p.}$ Hence, we have the probability mass function ${P_X(k) = (1 - p)^{k-1}p.}$

### Expected Value

~example~. A game: 1/6 of the time, the payout is ${\cash{1}.}$ 1/2 of time, the payout is ${\cash{2}.}$ 1/3 of the time, ${\cash{4}.}$

~question~. Playing ${n}$ times (where ${n}$ is very large), what's the average payout?
> ${(1/6)(\cash{1}) + (1/2)(\cash{2}) + (1/3)(\cash{4}) = \cash{2.5}.}$

The value 2.5 is an example of a __*random variable*__.




